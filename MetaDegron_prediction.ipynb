{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math, tempfile, datetime, time, copy, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from collections import Counter, defaultdict\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model \n",
    "from keras.models import model_from_json\n",
    "from math import log\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import multiprocessing.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_E3_degrons = {'CBL': ['CBL APS motif', 'CBL MET motif', 'CBL PTK motif'],\n",
    "                    'CDC20': ['APC D box', 'APC ABBA/Cdc20','APC ABBA motif','APC KEN box','APC TPR motif'],\n",
    "                    'COP1': ['COP1 motif'], 'DTL': ['DTL PIP motif 1', 'DTL PIP motif 2'],\n",
    "                    'CUL3': ['KLHL3/KLH2 motif', 'KLHL17 motif'], 'KLHL3': ['KLHL3/KLH2 motif'],\n",
    "                    'KLHL2': ['KLHL3/KLH2 motif'], 'KEAP1': ['KEAP1 motif 1', 'KEAP1 motif 2'],\n",
    "                    'KLHL17': ['KLHL17 motif'], 'MDM2': ['MDM2 motif'], 'VHL': ['VHL motif'],\n",
    "                    'FBXW7': ['FBXW7 motif 1', 'FBXW7 motif 2'], 'SKP2': ['SKP2 Fbox motif'],\n",
    "                    'BTRC': ['BTRCP motif'], 'SIAH2': ['SIAH motif'], 'SIAH1': ['SIAH motif'],\n",
    "                    'SPOP': ['SPOP motif'], 'FBXL2': ['FBXL2 motif'], 'FBXO31': ['FBX031 motif'],\n",
    "                    'NEDD4': ['ITCH motif'], 'ITCH': ['ITCH motif']}\n",
    "\n",
    "covariates =[\"ASA_SCORE\",\"DSS_SCORE\",\"FCONS_SCORE\",\"COIL\",\"ANCHOR_SCORE\",\"nflanking_ptms\",\"nflanking_ub_lysines\",\"HELIX\",\"STRAND\",\"RIG_SCORE\",\"Domain_pfam\"]\n",
    "order = [\"Entry\",\"Hit\",\"DEGRON\",\"E3\",\"START\",\"END\",\"Prob_DEGRON\",\"ID_in_UniProt\"]\n",
    "\n",
    "classifier_XGBoost  = \"./models/classifier_XGBoost.pickle\"\n",
    "uid_list = np.load('./supporting_file/uniprot_list.npy', allow_pickle = True)\n",
    "\n",
    "path_output_classes = (\"./supporting_file/elm_class_202309.txt\")\n",
    "df_dregon_types = pd.read_csv(path_output_classes,sep=\"\\t\")\n",
    "d_motifs = {}\n",
    "for index,row in df_dregon_types.iterrows():\n",
    "    d_motifs[row[\"Motif\"]]=re.compile(row[\"Regex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elmo_embedder():\n",
    "    def __init__(self, model_dir=\"./models/uniref50_v2\", weights=\"weights.hdf5\",\n",
    "                 options=\"options.json\", threads=100): \n",
    "        if threads == 100:\n",
    "            torch.set_num_threads(multiprocessing.cpu_count() // 2)\n",
    "        else:\n",
    "            torch.set_num_threads(threads)\n",
    "\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.weights = self.model_dir / weights\n",
    "        self.options = self.model_dir / options\n",
    "        self.seqvec = ElmoEmbedder(self.options, self.weights, cuda_device=-1)\n",
    "\n",
    "    def elmo_embedding(self, x, start=None, stop=None):\n",
    "        assert start is None and stop is None, \"deprecated to use start stop, please trim seqs beforehand\"\n",
    "\n",
    "        if type(x[0]) == str:\n",
    "            x = np.array([list(i.upper()) for i in x])\n",
    "        embedding = self.seqvec.embed_sentences(x)\n",
    "        X_parsed = []\n",
    "        for i in embedding:\n",
    "            X_parsed.append(i.mean(axis=0))\n",
    "        return X_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fasta_file):\n",
    "    try:\n",
    "        fp = open(fasta_file)\n",
    "    except IOError:\n",
    "        exit()\n",
    "    else:\n",
    "        fp = open(fasta_file)\n",
    "        lines = fp.readlines()\n",
    "        fasta_dict = {} \n",
    "        gene_id = \"\"\n",
    "        for line in lines:\n",
    "            if line[0] == '>':\n",
    "                if gene_id != \"\":\n",
    "                    fasta_dict[gene_id] = seq\n",
    "                seq = \"\"\n",
    "                gene_id = line.strip()[1:]\n",
    "            else:\n",
    "                seq += line.strip()        \n",
    "        fasta_dict[gene_id] = seq       \n",
    "    return fasta_dict  \n",
    "\n",
    "def AA_encoding(seq_extended):\n",
    "    amino = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ-\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(list(amino))\n",
    "    seq_transformed = np.array(\n",
    "        list(map(encoder.transform, np.array([list(i.upper()) for i in seq_extended]))))   \n",
    "    return seq_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model():\n",
    "    json_f = open(\"./models/degron_DL.json\", 'r')\n",
    "    loaded_model_json = json_f.read()\n",
    "    json_f.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights('./models/degron_DL.h5')\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting E3 ligase targeted degrons using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_write_result_data(fasta_file, out_file, degron_motif):\n",
    "    \n",
    "    ID_sequences = read_fasta(fasta_file)\n",
    "    l_results=[]\n",
    "    uid_degron = list(ID_sequences.keys())\n",
    "\n",
    "    for E3_query in degron_motif:\n",
    "        degron_motif = dict_E3_degrons[E3_query]\n",
    "        \n",
    "        for uid in uid_degron:\n",
    "            seq_local = ID_sequences[uid]\n",
    "            for motif in degron_motif:\n",
    "                for m in re.finditer(d_motifs[motif], seq_local):\n",
    "                    l_results.append([uid,E3_query,m.group(),motif,m.start()+1,m.end()])\n",
    "                \n",
    "    df_matches_seq = pd.DataFrame(l_results,columns=[\"Entry\",\"E3\",\"Hit\",\"DEGRON\",\"START\",\"END\"])   \n",
    "\n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    if len(df_matches_seq) > 0:\n",
    "        print('Deep learning models are making predictions...')\n",
    "        model_DL = import_model()\n",
    "        elmo_embedder = Elmo_embedder(threads=60)\n",
    "        shift, slicesize = 14, 29\n",
    "\n",
    "        d_nouid_degron_pos = {}\n",
    "        for index, row in df_matches_seq.iterrows():\n",
    "            if row[\"Entry\"] not in d_nouid_degron_pos.keys():\n",
    "                d_nouid_degron_pos[row[\"Entry\"]] = [\"_\".join([str(row[\"START\"]), str(row[\"END\"]), row[\"Hit\"], row[\"DEGRON\"],row[\"E3\"]])]\n",
    "            else:\n",
    "                d_nouid_degron_pos[row[\"Entry\"]].append(\"_\".join([str(row[\"START\"]), str(row[\"END\"]), row[\"Hit\"], row[\"DEGRON\"],row[\"E3\"]])) \n",
    "\n",
    "        nouid_degron = list(d_nouid_degron_pos.keys())\n",
    "        for index, uid in enumerate(nouid_degron):\n",
    "            headers = d_nouid_degron_pos[uid]\n",
    "            seq_local = ID_sequences[uid]\n",
    "            seq_len = len(seq_local)\n",
    "            seq_local = seq_local.upper()\n",
    "            seq_local_list = np.array(list(seq_local))\n",
    "\n",
    "            X_embedding = elmo_embedder.elmo_embedding(seq_local_list)\n",
    "            protein_pad_global = np.zeros((seq_len + (shift * 2), 1024), dtype=np.float32)\n",
    "\n",
    "            for i in range(0, seq_len, 1):\n",
    "                protein_pad_global[i + (shift)] = X_embedding[i]\n",
    "\n",
    "            protein_pad_local = [\"-\"] * (seq_len + (shift * 2))\n",
    "            for i in range(0, seq_len, 1):\n",
    "                protein_pad_local[i + (shift)] = seq_local[i]\n",
    "            protein_pad_local = \"\".join(protein_pad_local)\n",
    "\n",
    "            X_local, all_seq_transformed, all_seq_elmo_embedding = [], [], []\n",
    "            for head in headers:\n",
    "                head_arr = head.split(\"_\")\n",
    "                start_origin = int(head_arr[0])-1\n",
    "                stop_origin = int(head_arr[1])\n",
    "                motif = head_arr[2]\n",
    "                degron = head_arr[3]\n",
    "                E3_d = head_arr[-1]\n",
    "                start = int(head_arr[0]) -1 + shift\n",
    "                stop = int(head_arr[1]) + shift\n",
    "                median_pos = (start+stop-1)//2\n",
    "                slice_start = median_pos - slicesize // 2\n",
    "                slice_stop = slice_start + slicesize\n",
    "                query_seq = protein_pad_local[slice_start:slice_stop]\n",
    "                seq_transformed = AA_encoding([query_seq])\n",
    "                all_seq_transformed.append(seq_transformed)\n",
    "                seq_elmo_embedding = protein_pad_global[slice_start:slice_stop]\n",
    "                all_seq_elmo_embedding.append(seq_elmo_embedding)\n",
    "                X_local.append([uid, E3_d, motif, degron, start_origin+1, stop_origin])\n",
    "\n",
    "            probs_ = model_DL.predict([all_seq_elmo_embedding, all_seq_transformed]) \n",
    "            df_matches_seq_f = pd.DataFrame(X_local,columns=[\"Entry\",\"E3\",\"Hit\",\"DEGRON\",\"START\",\"END\"])             \n",
    "            df_matches_seq_f['Prob_DEGRON'] = probs_\n",
    "\n",
    "            all_data = pd.concat([all_data, df_matches_seq_f])\n",
    "        \n",
    "    tmp_folder = out_file # Please change this path to save result\n",
    "\n",
    "    all_data1 = all_data[[\"Entry\",\"E3\", \"Hit\",\"DEGRON\",\"START\",\"END\",\"Prob_DEGRON\"]]\n",
    "    all_data1['Prob_DEGRON'] =  all_data1['Prob_DEGRON'].astype(float)\n",
    "    # all_data1['Prob_DEGRON'] = all_data1['Prob_DEGRON'].apply(lambda x: format(x, '.4f'))\n",
    "    all_data2 = all_data1.sort_values(by=['Entry','Prob_DEGRON'],ascending=[True, False])\n",
    "    \n",
    "    re_names = {'E3': 'E3 ligase', 'Hit': 'Degron instance', 'DEGRON': 'Degron type',\n",
    "            'START': 'Start', 'END': 'End', 'Prob_DEGRON': 'Score'}\n",
    "    all_data2.rename(columns=re_names, inplace=True)    \n",
    "    all_data2 = all_data2.round(4)\n",
    "\n",
    "    path_output_dataframe = tmp_folder + '/prediction.txt'\n",
    "    all_data2.to_csv(path_output_dataframe,sep=\"\\t\",index=False)\n",
    "\n",
    "    print('Predictions completed, please check the results...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning models are making predictions...\n",
      "WARNING:tensorflow:From /public/home/hxu6/anaconda3/envs/tens37/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /public/home/hxu6/anaconda3/envs/tens37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 22:02:25.592504: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/gridview//pbs/dispatcher/lib:/opt/gridview//pbs/dispatcher/lib::/usr/local/lib64:/usr/local/lib:/usr/local/lib64:/usr/local/lib\n",
      "2024-05-12 22:02:25.592541: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-12 22:02:25.592562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node4): /proc/driver/nvidia/version does not exist\n",
      "2024-05-12 22:02:25.593086: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-05-12 22:02:25.622346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2024-05-12 22:02:25.643783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf28968110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-12 22:02:25.643822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /public/home/hxu6/anaconda3/envs/tens37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Predictions completed, please check the results...\n"
     ]
    }
   ],
   "source": [
    "degron_motif = ['CDC20','FBXW7']\n",
    "fasta_file = './data/test.fasta'\n",
    "out_file = './prediction'\n",
    "\n",
    "pred_and_write_result_data(fasta_file, out_file, degron_motif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting E3 ligase targeted degrons using XGBoost model trained on multimodal feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifically, the determination of residue-specific flexibility utilized the DynaMine software. Residue-specific solvent accessibility and secondary structures, including coiled coil and α-helix, were computed using the Spider2 tool. Protein disorder was assessed through the utilization of the IUPred software. The anchoring score of each degron was evaluated employing the ANCHOR program. Multiple sequence alignments (MSA) of orthologous proteins were acquired utilizing the Gopher tool from Bioware to calculate sequence conservation. Information pertaining to protein domains was retrieved from the Pfam database. Moreover, we evaluated the enrichment of important PTMs (phosphorylation and ubiquitination) within and around degrons. The experimentally verified PTMs information was downloaded from our constructed EPSD and PLMD resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed, please check the results...\n"
     ]
    }
   ],
   "source": [
    "out_file = './prediction'\n",
    "\n",
    "test_data = './data/test_properties.tsv'\n",
    "df_properties = pd.read_csv(test_data, sep=\"\\t\")\n",
    "\n",
    "covariates = ['solvent_accessibility', 'disorder', 'conservative_score', 'coiled_coil',\n",
    "              'anchoring_score', 'flanking_ptms', 'flanking_ub_lysine', \n",
    "              'a_helix', 'flexibility',  'structured_domain',  ]\n",
    "\n",
    "clf = pickle.load(open(classifier_XGBoost, \"rb\"))\n",
    "p_probs = clf.predict_proba(df_properties[covariates])\n",
    "df_properties[\"degron_prob\"] = [l[1] for l in p_probs]\n",
    "\n",
    "path_output_dataframe = out_file + '/prediction.txt'\n",
    "df_properties.to_csv(path_output_dataframe,sep=\"\\t\",index=False)\n",
    "\n",
    "print('Predictions completed, please check the results...')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
